{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BcNvzUyQRFB9"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Anomaly Detection and Time Series"
      ],
      "metadata": {
        "id": "Xot0WYDTRHE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Anomaly Detection? Explain its types (point, contextual, and\n",
        "collective anomalies) with examples.\n",
        "\n",
        "Answer: Anomaly Detection\n",
        "\n",
        "Anomaly Detection is the process of identifying data points, patterns, or observations that deviate significantly from normal behavior in a dataset. These unusual observations are called anomalies or outliers and often indicate errors, fraud, rare events, or system failures.\n",
        "\n",
        "It is widely used in:\n",
        "\n",
        "Fraud detection\n",
        "\n",
        "Network intrusion detection\n",
        "\n",
        "Medical diagnosis\n",
        "\n",
        "Industrial fault detection\n",
        "\n",
        "Types of Anomalies\n",
        "1. Point Anomaly\n",
        "\n",
        "A single data instance that is far from the rest of the data.\n",
        "\n",
        "- Definition:\n",
        "An individual data point is considered anomalous if it deviates significantly from normal data points.\n",
        "\n",
        "- Example:\n",
        "\n",
        "In a dataset of daily bank transactions where most amounts are between â‚¹500â€“â‚¹10,000, a single transaction of â‚¹10,00,000 is a point anomaly.\n",
        "\n",
        "In temperature readings mostly around 25Â°C, a sudden reading of 70Â°C is a point anomaly.\n",
        "\n",
        "- Use case:\n",
        "\n",
        "Credit card fraud detection\n",
        "\n",
        "Sensor malfunction detection\n",
        "\n",
        "2. Contextual Anomaly\n",
        "\n",
        "A data point is anomalous only in a specific context (such as time, location, or condition).\n",
        "\n",
        "- Definition:\n",
        "\n",
        "The anomaly depends on contextual information, not just the value itself.\n",
        "\n",
        " Example:\n",
        "\n",
        "25Â°C temperature is normal in summer but anomalous in winter.\n",
        "\n",
        "High electricity usage during the middle of the night may be abnormal but normal during daytime.\n",
        "\n",
        "- Use case:\n",
        "\n",
        "Weather monitoring\n",
        "\n",
        "Energy consumption analysis\n",
        "\n",
        "Health monitoring (heart rate during rest vs exercise)\n",
        "\n",
        "3. Collective Anomaly\n",
        "\n",
        "A group of related data points together forms an anomaly, even if individual points seem normal.\n",
        "\n",
        "- Definition:\n",
        "\n",
        "A sequence or collection of data points is anomalous as a whole.\n",
        "\n",
        "- Example:\n",
        "\n",
        "A sudden pattern of small but repeated login failures may indicate a cyber attack.\n",
        "\n",
        "Continuous slight vibration readings over time that together indicate machine failure.\n",
        "\n",
        " Use case:\n",
        "\n",
        "Network traffic analysis\n",
        "\n",
        "Time-series fault detection\n",
        "\n",
        "Fraud detection over transaction sequences\n",
        "| Type               | Description                    | Example                    |\n",
        "| ------------------ | ------------------------------ | -------------------------- |\n",
        "| Point Anomaly      | Single abnormal data point     | One huge bank transaction  |\n",
        "| Contextual Anomaly | Abnormal in a specific context | High temperature in winter |\n",
        "| Collective Anomaly | Group of abnormal points       | Repeated login failures    |\n",
        "\n",
        "\n",
        "In short:\n",
        "\n",
        "Point â†’ unusual single value\n",
        "\n",
        "Contextual â†’ unusual due to context\n",
        "\n",
        "Collective â†’ unusual pattern over time\n",
        "\n",
        "\n",
        "Question 2: Compare Isolation Forest, DBSCAN, and Local Outlier Factor in terms of their approach and suitable use cases.\n",
        "\n",
        "Answer: Isolation Forest, DBSCAN, and Local Outlier Factor are popular unsupervised anomaly detection techniques, but they differ in how they detect anomalies and where they are best used.\n",
        "\n",
        "1. Isolation Forest (IF)\n",
        "\n",
        "Approach\n",
        "\n",
        "- Based on the idea that anomalies are easier to isolate than normal points.\n",
        "\n",
        "- Uses an ensemble of random decision trees.\n",
        "\n",
        "- Anomalies require fewer splits to be isolated in the tree.\n",
        "\n",
        "- Does not rely on distance or density.\n",
        "\n",
        "Strengths\n",
        "\n",
        "- Works well with high-dimensional data.\n",
        "\n",
        "- Scales efficiently to large datasets.\n",
        "\n",
        "- Handles irrelevant features better than distance-based methods.\n",
        "\n",
        "Limitations\n",
        "\n",
        "- Less interpretable.\n",
        "\n",
        "- May struggle when anomalies are not well separated.\n",
        "\n",
        "Suitable Use Cases\n",
        "\n",
        "- Fraud detection\n",
        "\n",
        "- Network intrusion detection\n",
        "\n",
        "- Large-scale log analysis\n",
        "\n",
        "2. DBSCAN (Density-Based Spatial Clustering of Applications with Noise)\n",
        "\n",
        "Approach\n",
        "\n",
        "- Density-based clustering algorithm.\n",
        "\n",
        "- Points in low-density regions are labeled as noise (anomalies).\n",
        "\n",
        "- Requires two parameters: Îµ (epsilon) and min_samples.\n",
        "\n",
        "Strengths\n",
        "\n",
        "- Can detect arbitrarily shaped clusters.\n",
        "\n",
        "- Naturally identifies noise points as anomalies.\n",
        "\n",
        "- No need to specify the number of clusters.\n",
        "\n",
        "Limitations\n",
        "\n",
        "- Sensitive to parameter selection.\n",
        "\n",
        "- Performs poorly with varying density.\n",
        "\n",
        "- Struggles in high-dimensional spaces.\n",
        "\n",
        "Suitable Use Cases\n",
        "\n",
        "- Spatial data analysis\n",
        "\n",
        "- Geographical anomaly detection\n",
        "\n",
        "- Image segmentation\n",
        "\n",
        "3. Local Outlier Factor (LOF)\n",
        "\n",
        "Approach\n",
        "\n",
        "- Density-based anomaly detection.\n",
        "\n",
        "- Compares the local density of a point with its neighbors.\n",
        "\n",
        "- Points with much lower density than neighbors are considered anomalies.\n",
        "\n",
        "Strengths\n",
        "\n",
        "- Detects local anomalies effectively.\n",
        "\n",
        "- Works well when global density assumptions fail.\n",
        "\n",
        "Limitations\n",
        "\n",
        "- Computationally expensive.\n",
        "\n",
        "- Sensitive to choice of k (number of neighbors).\n",
        "\n",
        "- Not ideal for very large datasets.\n",
        "\n",
        "Suitable Use Cases\n",
        "\n",
        "- Credit card fraud detection\n",
        "\n",
        "- Sensor data anomaly detection\n",
        "\n",
        "- Healthcare monitoring\n",
        "\n",
        "| Aspect                | Isolation Forest            | DBSCAN                     | Local Outlier Factor     |\n",
        "| --------------------- | --------------------------- | -------------------------- | ------------------------ |\n",
        "| Core Idea             | Isolation via random splits | Density-based clustering   | Local density comparison |\n",
        "| Anomaly Type          | Global anomalies            | Low-density (noise) points | Local anomalies          |\n",
        "| Scalability           | High                        | Medium                     | Lowâ€“Medium               |\n",
        "| High-Dimensional Data | Good                        | Poor                       | Poor                     |\n",
        "| Parameter Sensitivity | Low                         | High                       | Medium                   |\n",
        "| Output                | Anomaly score               | Cluster + noise            | Anomaly score            |\n",
        "\n",
        "\n",
        "Key Takeaway\n",
        "\n",
        "Isolation Forest â†’ Best for large, high-dimensional datasets\n",
        "\n",
        "DBSCAN â†’ Best for spatial data and cluster-based anomalies\n",
        "\n",
        "LOF â†’ Best for local density-based anomalies\n",
        "\n",
        "Question 3: What are the key components of a Time Series? Explain each with one\n",
        "example.\n",
        "\n",
        "Answer : A Time Series is a sequence of data points recorded at regular time intervals (daily, monthly, yearly, etc.).\n",
        "To understand and analyze time-series data effectively, it is usually decomposed into four key components.\n",
        "\n",
        "1. Trend (T)\n",
        "\n",
        "- What it is:\n",
        "\n",
        "The long-term direction of the data over time (upward, downward, or constant).\n",
        "\n",
        "- Example:\n",
        "\n",
        "A steady increase in mobile phone users over the last 10 years.\n",
        "\n",
        "Rising annual sales of an e-commerce company.\n",
        "\n",
        "- Shows overall growth or decline.\n",
        "\n",
        "2. Seasonality (S)\n",
        "\n",
        "- What it is:\n",
        "\n",
        "Regular and repeating patterns that occur at fixed intervals (daily, weekly, monthly, yearly).\n",
        "\n",
        "- Example:\n",
        "\n",
        "Ice cream sales increase every summer.\n",
        "\n",
        "Higher electricity usage every evening.\n",
        "\n",
        "- Occurs due to seasonal or calendar effects.\n",
        "\n",
        "3. Cyclical Component (C)\n",
        "\n",
        "- What it is:\n",
        "\n",
        "Fluctuations that occur over longer and irregular periods, usually influenced by economic or business cycles.\n",
        "\n",
        "- Example:\n",
        "\n",
        "Economic boom and recession cycles affecting stock prices.\n",
        "\n",
        "Automobile sales rising and falling with economic conditions.\n",
        "\n",
        "- No fixed period like seasonality.\n",
        "\n",
        "4. Irregular / Noise (I)\n",
        "\n",
        "- What it is:\n",
        "\n",
        "Random, unpredictable variations that cannot be explained by trend, seasonality, or cycles.\n",
        "\n",
        " Example:\n",
        "\n",
        "Sudden drop in airline bookings due to a natural disaster or pandemic.\n",
        "\n",
        "Unexpected system failure affecting website traffic.\n",
        "\n",
        " Pure randomness or one-time events.\n",
        " | Component   | Meaning                      | Example                 |\n",
        "| ----------- | ---------------------------- | ----------------------- |\n",
        "| Trend       | Long-term movement           | Growth in online users  |\n",
        "| Seasonality | Repeating short-term pattern | Summer ice cream sales  |\n",
        "| Cyclical    | Long-term irregular cycles   | Business cycles         |\n",
        "| Irregular   | Random noise                 | Natural disaster impact |\n",
        "\n",
        "In short:\n",
        "\n",
        "A time series can be represented as:\n",
        "\n",
        "Additive model:\n",
        "\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘‡\n",
        "+\n",
        "ğ‘†\n",
        "+\n",
        "ğ¶\n",
        "+\n",
        "ğ¼\n",
        "Y=T+S+C+I\n",
        "\n",
        "Multiplicative model:\n",
        "\n",
        "ğ‘Œ\n",
        "=\n",
        "ğ‘‡\n",
        "Ã—\n",
        "ğ‘†\n",
        "Ã—\n",
        "ğ¶\n",
        "Ã—\n",
        "ğ¼\n",
        "Y=TÃ—SÃ—CÃ—I\n",
        "\n",
        "\n",
        "\n",
        "Question 4: Define Stationary in time series. How can you test and transform a\n",
        "non-stationary series into a stationary one?\n",
        "\n",
        "Answer : A time series is called stationary if its statistical properties remain constant over time.\n",
        "\n",
        "Key characteristics of a stationary series:\n",
        "\n",
        "Constant mean over time\n",
        "\n",
        "Constant variance over time\n",
        "\n",
        "Constant autocovariance (correlation structure depends only on lag, not time)\n",
        "\n",
        "- Stationarity is important because most time-series models (ARIMA, SARIMA) assume the data is stationary.\n",
        "\n",
        "How to Test Stationarity\n",
        "\n",
        "1. Visual Inspection\n",
        "\n",
        "Plot the time series.\n",
        "\n",
        "Look for trend, seasonality, or changing variance.\n",
        "\n",
        "If present â†’ likely non-stationary.\n",
        "\n",
        "- Example: Upward trending sales data.\n",
        "\n",
        "2. Augmented Dickey-Fuller (ADF) Test\n",
        "\n",
        "Null hypothesis (Hâ‚€): Series is non-stationary.\n",
        "\n",
        "Alternative hypothesis (Hâ‚): Series is stationary.\n",
        "\n",
        "- If p-value < 0.05 â†’ reject Hâ‚€ â†’ series is stationary.\n",
        "\n",
        "3. KPSS Test\n",
        "\n",
        "Null hypothesis (Hâ‚€): Series is stationary.\n",
        "\n",
        "Alternative hypothesis (Hâ‚): Series is non-stationary.\n",
        "\n",
        "- If p-value > 0.05 â†’ series is stationary.\n",
        "\n",
        "- ADF and KPSS together give more reliable results.\n",
        "\n",
        "How to Transform a Non-Stationary Series into a Stationary One\n",
        "1. Differencing\n",
        "\n",
        "Removes trend by subtracting previous values.\n",
        "\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "â€²\n",
        "=\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "1\n",
        "Y\n",
        "t\n",
        "â€²\n",
        "\tâ€‹\n",
        "\n",
        "=Y\n",
        "t\n",
        "\tâ€‹\n",
        "\n",
        "âˆ’Y\n",
        "tâˆ’1\n",
        "\tâ€‹\n",
        "\n",
        "\n",
        "First-order differencing is most common.\n",
        "\n",
        "Seasonal differencing for seasonal data.\n",
        "\n",
        "- Example: Stock prices â†’ price changes.\n",
        "\n",
        "2. Detrending\n",
        "\n",
        "Remove trend using regression or moving averages.\n",
        "\n",
        "- Example: Subtracting fitted trend line from sales data.\n",
        "\n",
        "3. Transformation (Log / Power Transform)\n",
        "\n",
        "Stabilizes changing variance.\n",
        "\n",
        "- Examples:\n",
        "\n",
        "Log transformation: log(y)\n",
        "\n",
        "Square root, Box-Cox transformation\n",
        "\n",
        "Used when variance increases with time.\n",
        "\n",
        "4. Seasonal Adjustment\n",
        "\n",
        "Remove seasonal patterns using seasonal differencing or decomposition.\n",
        "\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "ğ‘ \n",
        "Y\n",
        "t\n",
        "\tâ€‹\n",
        "\n",
        "âˆ’Y\n",
        "tâˆ’s\n",
        "\tâ€‹\n",
        "\n",
        "\n",
        "where s = seasonal period (e.g., 12 for monthly data).\n",
        "\n",
        "| Method                | Purpose                |\n",
        "| --------------------- | ---------------------- |\n",
        "| Differencing          | Remove trend           |\n",
        "| Seasonal differencing | Remove seasonality     |\n",
        "| Log / Box-Cox         | Stabilize variance     |\n",
        "| Detrending            | Remove long-term trend |\n",
        "\n",
        "In short:\n",
        "\n",
        "Stationary series â†’ constant mean, variance, and autocorrelation\n",
        "\n",
        "ADF test: p < 0.05 â†’ stationary\n",
        "\n",
        "KPSS test: p > 0.05 â†’ stationary\n",
        "\n",
        "Differencing + transformations make series stationary\n",
        "\n",
        "\n",
        "Question 5: Differentiate between AR, MA, ARIMA, SARIMA, and SARIMAX models in\n",
        "terms of structure and application.\n",
        "\n",
        "Answer : These models are widely used for time-series forecasting. They mainly differ in structure (components used) and applications (type of data they handle).\n",
        "\n",
        "1. AR (AutoRegressive) Model\n",
        "Structure\n",
        "\n",
        "Uses past values of the series to predict the current value.\n",
        "\n",
        "Order = p\n",
        "\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "=\n",
        "ğ‘\n",
        "+\n",
        "ğœ™\n",
        "1\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "1\n",
        "+\n",
        "ğœ™\n",
        "2\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "2\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğœ™\n",
        "ğ‘\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "ğ‘\n",
        "+\n",
        "ğœ–\n",
        "ğ‘¡\n",
        "Y\n",
        "t\n",
        "\tâ€‹\n",
        "\n",
        "=c+Ï•\n",
        "1\n",
        "\tâ€‹\n",
        "\n",
        "Y\n",
        "tâˆ’1\n",
        "\tâ€‹\n",
        "\n",
        "+Ï•\n",
        "2\n",
        "\tâ€‹\n",
        "\n",
        "Y\n",
        "tâˆ’2\n",
        "\tâ€‹\n",
        "\n",
        "+â‹¯+Ï•\n",
        "p\n",
        "\tâ€‹\n",
        "\n",
        "Y\n",
        "tâˆ’p\n",
        "\tâ€‹\n",
        "\n",
        "+Ïµ\n",
        "t\n",
        "\tâ€‹\n",
        "\n",
        "Application\n",
        "\n",
        "Suitable when the series is stationary.\n",
        "\n",
        "When current value depends strongly on past values.\n",
        "\n",
        "- Example: Predicting temperature using previous daysâ€™ temperatures.\n",
        "\n",
        "2. MA (Moving Average) Model\n",
        "Structure\n",
        "\n",
        "Uses past forecast errors (residuals).\n",
        "\n",
        "Order = q\n",
        "\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "=\n",
        "ğ‘\n",
        "+\n",
        "ğœƒ\n",
        "1\n",
        "ğœ–\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "1\n",
        "+\n",
        "ğœƒ\n",
        "2\n",
        "ğœ–\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "2\n",
        "+\n",
        "â‹¯\n",
        "+\n",
        "ğœƒ\n",
        "ğ‘\n",
        "ğœ–\n",
        "ğ‘¡\n",
        "âˆ’\n",
        "ğ‘\n",
        "+\n",
        "ğœ–\n",
        "ğ‘¡\n",
        "Y\n",
        "t\n",
        "\tâ€‹\n",
        "\n",
        "=c+Î¸\n",
        "1\n",
        "\tâ€‹\n",
        "\n",
        "Ïµ\n",
        "tâˆ’1\n",
        "\tâ€‹\n",
        "\n",
        "+Î¸\n",
        "2\n",
        "\tâ€‹\n",
        "\n",
        "Ïµ\n",
        "tâˆ’2\n",
        "\tâ€‹\n",
        "\n",
        "+â‹¯+Î¸\n",
        "q\n",
        "\tâ€‹\n",
        "\n",
        "Ïµ\n",
        "tâˆ’q\n",
        "\tâ€‹\n",
        "\n",
        "+Ïµ\n",
        "t\n",
        "\tâ€‹\n",
        "\n",
        "Application\n",
        "\n",
        "Stationary series with random shocks.\n",
        "\n",
        "Useful when errors show correlation.\n",
        "\n",
        "- Example: Modeling noise in financial time series.\n",
        "\n",
        "3. ARIMA (AutoRegressive Integrated Moving Average)\n",
        "Structure\n",
        "\n",
        "Combination of AR + MA + Differencing (I).\n",
        "\n",
        "Order = (p, d, q)\n",
        "\n",
        "ğ´\n",
        "ğ‘…\n",
        "ğ¼\n",
        "ğ‘€\n",
        "ğ´\n",
        "(\n",
        "ğ‘\n",
        ",\n",
        "ğ‘‘\n",
        ",\n",
        "ğ‘\n",
        ")\n",
        "ARIMA(p,d,q)\n",
        "\n",
        "d = number of differences to make the series stationary.\n",
        "\n",
        "Application\n",
        "\n",
        "Non-stationary data without seasonality.\n",
        "\n",
        "One of the most commonly used forecasting models.\n",
        "\n",
        "- Example: Stock prices, sales data without seasonal effects.\n",
        "\n",
        "4. SARIMA (Seasonal ARIMA)\n",
        "Structure\n",
        "\n",
        "Extends ARIMA to include seasonality.\n",
        "\n",
        "Order = (p, d, q) Ã— (P, D, Q, s)\n",
        "\n",
        "Where:\n",
        "\n",
        "(P, D, Q) = seasonal AR, differencing, MA\n",
        "\n",
        "s = seasonal period (e.g., 12 for monthly data)\n",
        "\n",
        "Application\n",
        "\n",
        "Data with clear seasonal patterns.\n",
        "\n",
        "- Example: Monthly airline passenger data, seasonal sales.\n",
        "\n",
        "5. SARIMAX (Seasonal ARIMA with Exogenous Variables)\n",
        "Structure\n",
        "\n",
        "SARIMA + external (exogenous) variables (X).\n",
        "\n",
        "Incorporates factors other than past values.\n",
        "\n",
        "ğ‘Œ\n",
        "ğ‘¡\n",
        "=\n",
        "ğ‘†\n",
        "ğ´\n",
        "ğ‘…\n",
        "ğ¼\n",
        "ğ‘€\n",
        "ğ´\n",
        "+\n",
        "ğ›½\n",
        "ğ‘‹\n",
        "ğ‘¡\n",
        "Y\n",
        "t\n",
        "\tâ€‹\n",
        "\n",
        "=SARIMA+Î²X\n",
        "t\n",
        "\tâ€‹\n",
        "\n",
        "Application\n",
        "\n",
        "When the time series is influenced by external factors.\n",
        "\n",
        "- Example: Sales forecasting using price, promotions, or holidays.\n",
        "\n",
        "Key Takeaway\n",
        "\n",
        "AR / MA â†’ stationary data\n",
        "\n",
        "ARIMA â†’ non-stationary, no seasonality\n",
        "\n",
        "SARIMA â†’ seasonal time series\n",
        "\n",
        "SARIMAX â†’ seasonal + external influences\n",
        "\n",
        "\n",
        "Question 6: Load a time series dataset (e.g., AirPassengers), plot the original series, and decompose it into trend, seasonality, and residual components.\n",
        "\n",
        "Answer: Below is a complete Python example using the AirPassengers dataset to:\n",
        "\n",
        "Load the time series\n",
        "\n",
        "Plot the original series\n",
        "\n",
        "Decompose it into Trend, Seasonality, and Residuals\n",
        "\n",
        "Step 1: Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "\n",
        "Step 2: Load AirPassengers Dataset\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\",\n",
        "    parse_dates=[\"Month\"],\n",
        "    index_col=\"Month\"\n",
        ")\n",
        "\n",
        "data.rename(columns={\"Passengers\": \"Passengers\"}, inplace=True)\n",
        "\n",
        "Step 3: Plot Original Time Series\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(data, label=\"Air Passengers\")\n",
        "plt.title(\"AirPassengers Time Series\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Passengers\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Observation:\n",
        "\n",
        "Clear upward trend\n",
        "\n",
        "Strong seasonal pattern (yearly)\n",
        "\n",
        "Step 4: Decompose the Time Series\n",
        "\n",
        "Since variance increases over time, we use multiplicative decomposition.\n",
        "\n",
        "decomposition = seasonal_decompose(\n",
        "    data[\"Passengers\"],\n",
        "    model=\"multiplicative\",\n",
        "    period=12\n",
        ")\n",
        "\n",
        "Step 5: Plot Decomposed Components\n",
        "\n",
        "decomposition.plot()\n",
        "plt.show()\n",
        "\n",
        "| Component   | Meaning                  | Interpretation in AirPassengers |\n",
        "| ----------- | ------------------------ | ------------------------------- |\n",
        "| Trend       | Long-term movement       | Growth in air travel            |\n",
        "| Seasonality | Repeating yearly pattern | Holiday & travel seasons        |\n",
        "| Residual    | Random noise             | Unexpected fluctuations         |\n",
        "\n",
        "\n",
        "Key Takeaways (Exam-Ready)\n",
        "\n",
        "AirPassengers data is non-stationary\n",
        "\n",
        "Shows trend + seasonality\n",
        "\n",
        "Multiplicative model is preferred due to increasing variance\n",
        "\n",
        "Decomposition helps in model selection (SARIMA)\n",
        "\n",
        "\n",
        "Question 7: Apply Isolation Forest on a numerical dataset (e.g., NYC Taxi Fare) to detect anomalies. Visualize the anomalies on a 2D scatter plot.\n",
        "\n",
        "AnswerBelow is a complete, exam-ready workflow where we apply Isolation Forest on a numerical NYC Taxiâ€“like dataset and visualize anomalies using a 2D scatter plot.\n",
        "\n",
        "Step 1: Dataset Description\n",
        "\n",
        "We use two numerical features commonly found in NYC Taxi data:\n",
        "\n",
        "Trip Distance (km)\n",
        "\n",
        "Fare Amount\n",
        "\n",
        "Some abnormally high fares/distances are injected to simulate anomalies.\n",
        "\n",
        "Step 2: Apply Isolation Forest\n",
        "\n",
        "Isolation Forest isolates anomalies using random splits\n",
        "\n",
        "Anomalies are easier to isolate â†’ shorter path length\n",
        "\n",
        "We assume 5% contamination\n",
        "\n",
        "Step 3: Visualization\n",
        "\n",
        "X-axis â†’ Trip Distance\n",
        "\n",
        "Y-axis â†’ Fare Amount\n",
        "\n",
        "Normal points â†’ cluster\n",
        "\n",
        "Anomalies â†’ clearly separated points\n",
        "\n",
        "(Scatter plot shown above ğŸ‘†)\n",
        "\n",
        "Interpretation of Results\n",
        "\n",
        "Most taxi trips follow a linear fareâ€“distance relationship\n",
        "\n",
        "Points with very high fare for long distances are flagged as anomalies\n",
        "\n",
        "These may indicate:\n",
        "\n",
        "Meter faults\n",
        "\n",
        "Data entry errors\n",
        "\n",
        "Fraudulent rides\n",
        "\n",
        "Why Isolation Forest is Suitable Here\n",
        "\n",
        "- Works well with numerical data\n",
        "- Scales to large datasets (NYC Taxi is huge)\n",
        "-  No assumption of data distribution\n",
        "-  Effective in high-dimensional settings\n",
        "\n",
        "Exam-Ready Conclusion\n",
        "\n",
        "Isolation Forest successfully detects anomalous taxi trips by isolating rare fareâ€“distance combinations. The 2D scatter plot clearly highlights anomalies as isolated points far from the normal data cluster.\n",
        "\n",
        "\n",
        "Question 8: Train a SARIMA model on the monthly airline passengers dataset.\n",
        "Forecast the next 12 months and visualize the results.\n",
        "\n",
        "Answer : Objective\n",
        "\n",
        "Train a SARIMA model on monthly airline passengers data\n",
        "\n",
        "Forecast the next 12 months\n",
        "\n",
        "Visualize original data and forecast\n",
        "\n",
        "Why SARIMA?\n",
        "\n",
        "The AirPassengers dataset shows:\n",
        "\n",
        "Trend (increasing passengers)\n",
        "\n",
        "Seasonality (12-month cycle)\n",
        "\n",
        "Hence, SARIMA(p,d,q)(P,D,Q,12) is appropriate.\n",
        "\n",
        "Python Implementation\n",
        "\n",
        "Step 1: Import Libraries\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from statsmodels.tsa.statespace.sarimax import SARIMAX\n",
        "\n",
        "Step 2: Load Dataset\n",
        "\n",
        "data = pd.read_csv(\n",
        "    \"https://raw.githubusercontent.com/jbrownlee/Datasets/master/airline-passengers.csv\",\n",
        "    parse_dates=[\"Month\"],\n",
        "    index_col=\"Month\"\n",
        ")\n",
        "\n",
        "series = data[\"Passengers\"]\n",
        "\n",
        "\n",
        "Step 3: Train SARIMA Model\n",
        "\n",
        "model = SARIMAX(\n",
        "    series,\n",
        "    order=(1,1,1),\n",
        "    seasonal_order=(1,1,1,12)\n",
        ")\n",
        "\n",
        "results = model.fit()\n",
        "\n",
        "Step 4: Forecast Next 12 Months\n",
        "\n",
        "forecast = results.get_forecast(steps=12)\n",
        "forecast_values = forecast.predicted_mean\n",
        "\n",
        "Step 5: Visualization\n",
        "\n",
        "plt.figure()\n",
        "plt.plot(series, label=\"Observed\")\n",
        "plt.plot(forecast_values, label=\"Forecast (12 months)\")\n",
        "plt.xlabel(\"Year\")\n",
        "plt.ylabel(\"Number of Passengers\")\n",
        "plt.title(\"SARIMA Forecast on AirPassengers Dataset\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Result Interpretation\n",
        "\n",
        "Forecast continues the upward trend\n",
        "\n",
        "Seasonal pattern is preserved\n",
        "\n",
        "Suitable for real-world airline demand forecasting\n",
        "\n",
        "\n",
        "Question 9: Apply Local Outlier Factor (LOF) on any numerical dataset to detect\n",
        "anomalies and visualize them using matplotlib.\n",
        "\n",
        "Answer: Below is a complete Python example where we:\n",
        "\n",
        "Create a numerical dataset\n",
        "\n",
        "Apply Local Outlier Factor (LOF)\n",
        "\n",
        "Visualize anomalies using matplotlib\n",
        "\n",
        "Include code + output explanation (exam-ready)\n",
        "\n",
        "Concept (1â€“2 lines for exam)\n",
        "\n",
        "Local Outlier Factor (LOF) detects anomalies by comparing the local density of a point with the density of its nearest neighbors. Points with significantly lower density are labeled as outliers.\n",
        "\n",
        "Python Code (with Visualization)\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.neighbors import LocalOutlierFactor\n",
        "\n",
        "# Step 1: Create a synthetic numerical dataset\n",
        "np.random.seed(42)\n",
        "\n",
        "# Normal data points\n",
        "X_normal = 0.3 * np.random.randn(200, 2)\n",
        "\n",
        "# Anomalies\n",
        "X_anomalies = np.random.uniform(low=-4, high=4, size=(20, 2))\n",
        "\n",
        "# Combine dataset\n",
        "X = np.vstack([X_normal, X_anomalies])\n",
        "\n",
        "# Step 2: Apply Local Outlier Factor\n",
        "lof = LocalOutlierFactor(n_neighbors=20, contamination=0.1)\n",
        "y_pred = lof.fit_predict(X)\n",
        "\n",
        "# Step 3: Separate normal points and anomalies\n",
        "normal_points = X[y_pred == 1]\n",
        "anomalies = X[y_pred == -1]\n",
        "\n",
        "# Step 4: Visualization\n",
        "plt.figure()\n",
        "plt.scatter(normal_points[:, 0], normal_points[:, 1], label=\"Normal Data\")\n",
        "plt.scatter(anomalies[:, 0], anomalies[:, 1], label=\"Anomalies\")\n",
        "plt.xlabel(\"Feature 1\")\n",
        "plt.ylabel(\"Feature 2\")\n",
        "plt.title(\"Anomaly Detection using Local Outlier Factor (LOF)\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "Output Explanation\n",
        "\n",
        "Normal points form a dense cluster near the center\n",
        "\n",
        "Anomalies are isolated points with low local density\n",
        "\n",
        "LOF correctly identifies points that\n",
        " are locally different, even if they are not extreme globally\n",
        "\n",
        "\n",
        " Question 10: You are working as a data scientist for a power grid monitoring company.\n",
        "Your goal is to forecast energy demand and also detect abnormal spikes or drops in\n",
        "real-time consumption data collected every 15 minutes. The dataset includes features\n",
        "like timestamp, region, weather conditions, and energy usage.\n",
        "Explain your real-time data science workflow:\n",
        "â— How would you detect anomalies in this streaming data (Isolation Forest / LOF /\n",
        "DBSCAN)?\n",
        "â— Which time series model would you use for short-term forecasting (ARIMA /\n",
        "SARIMA / SARIMAX)?\n",
        "â— How would you validate and monitor the performance over time?\n",
        "â— How would this solution help business decisions or operations?\n",
        "\n",
        "Answer : As a data scientist in a power grid monitoring company, the objective is twofold:\n",
        "1ï¸ Forecast short-term energy demand\n",
        "2ï¸ Detect abnormal spikes or drops in real-time consumption\n",
        "\n",
        "Below is a practical, end-to-end workflow addressing streaming data, modeling, validation, and business impact.\n",
        "\n",
        "1. Real-Time Anomaly Detection in Streaming Data\n",
        "Recommended Approach: Isolation Forest (Primary) + LOF (Secondary)\n",
        "Why Isolation Forest?\n",
        "\n",
        "Works well with high-frequency, high-volume streaming data\n",
        "\n",
        "Fast and scalable\n",
        "\n",
        "No distance calculation â†’ efficient in real time\n",
        "\n",
        "Can be incrementally retrained on rolling windows\n",
        "\n",
        "How it works in practice:\n",
        "\n",
        "Train Isolation Forest on a sliding window of recent normal data (e.g., last 7 days)\n",
        "\n",
        "Features used:\n",
        "\n",
        "Energy usage\n",
        "\n",
        "Temperature, humidity\n",
        "\n",
        "Time-based features (hour, day)\n",
        "\n",
        "Flag points with high anomaly scores as spikes or drops\n",
        "\n",
        "Where LOF Fits\n",
        "\n",
        "Used for local anomalies within a region\n",
        "\n",
        "Helpful when neighboring regions show different usage patterns\n",
        "\n",
        "- DBSCAN is less suitable\n",
        "\n",
        "Computationally expensive\n",
        "\n",
        "Sensitive to parameter tuning\n",
        "\n",
        "Not ideal for real-time streaming\n",
        "\n",
        "2. Short-Term Energy Demand Forecasting Model\n",
        "Best Choice: SARIMAX\n",
        "Why SARIMAX?\n",
        "\n",
        "Energy demand shows:\n",
        "\n",
        "Trend\n",
        "\n",
        "Strong daily & weekly seasonality\n",
        "\n",
        "External influence from weather\n",
        "\n",
        "SARIMAX supports exogenous variables\n",
        "\n",
        "Model Structure\n",
        "ğ‘†\n",
        "ğ´\n",
        "ğ‘…\n",
        "ğ¼\n",
        "ğ‘€\n",
        "ğ´\n",
        "ğ‘‹\n",
        "(\n",
        "ğ‘\n",
        ",\n",
        "ğ‘‘\n",
        ",\n",
        "ğ‘\n",
        ")\n",
        "(\n",
        "ğ‘ƒ\n",
        ",\n",
        "ğ·\n",
        ",\n",
        "ğ‘„\n",
        ",\n",
        "ğ‘ \n",
        ")\n",
        "+\n",
        "ğ‘‹\n",
        "SARIMAX(p,d,q)(P,D,Q,s)+X\n",
        "\n",
        "Exogenous variables (X):\n",
        "\n",
        "Temperature\n",
        "\n",
        "Humidity\n",
        "\n",
        "Wind speed\n",
        "\n",
        "Region-level indicators\n",
        "\n",
        "Holiday flags\n",
        "\n",
        "â± Forecast horizon:\n",
        "\n",
        "15 minutes to 24 hours ahead (rolling forecast)\n",
        "\n",
        "3. Validation & Monitoring Over Time\n",
        "Model Validation\n",
        "\n",
        "Time-series cross-validation (rolling window)\n",
        "\n",
        "Metrics:\n",
        "\n",
        "MAE / RMSE â†’ operational accuracy\n",
        "\n",
        "MAPE â†’ relative error across regions\n",
        "\n",
        "Anomaly Detection Validation\n",
        "\n",
        "Compare detected anomalies with:\n",
        "\n",
        "Historical outage logs\n",
        "\n",
        "Maintenance events\n",
        "\n",
        "Track:\n",
        "\n",
        "False positives\n",
        "\n",
        "Missed critical events\n",
        "\n",
        "Continuous Monitoring\n",
        "\n",
        "Monitor:\n",
        "\n",
        "Prediction error drift\n",
        "\n",
        "Anomaly rate over time\n",
        "\n",
        "Retrain models:\n",
        "\n",
        "Daily or weekly\n",
        "\n",
        "Trigger alerts when:\n",
        "\n",
        "Error exceeds threshold\n",
        "\n",
        "Anomaly frequency spikes\n",
        "\n",
        "4. Business & Operational Impact\n",
        "How This Helps the Business\n",
        "\n",
        "- Grid Stability\n",
        "\n",
        "Early detection of abnormal spikes prevents blackouts\n",
        "\n",
        "- Cost Optimization\n",
        "\n",
        "Accurate forecasts reduce overproduction and wastage\n",
        "\n",
        "- Faster Incident Response\n",
        "\n",
        "Real-time alerts enable proactive maintenance\n",
        "\n",
        "- Improved Load Balancing\n",
        "\n",
        "Region-wise forecasting supports smart energy distribution\n",
        "\n",
        " Regulatory Compliance\n",
        "\n",
        "Better reporting and reliability metrics\n",
        "\n",
        "Final Architecture Summary (Interview-Ready)\n",
        "Component\tChoice\n",
        "Anomaly Detection\tIsolation Forest + LOF\n",
        "Forecasting Model\tSARIMAX\n",
        "Data Handling\tSliding window, streaming\n",
        "Validation\tRolling CV, MAE/RMSE\n",
        "Business Value\tStability, cost savings, reliability\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "cyoJ96llRSBi"
      }
    }
  ]
}